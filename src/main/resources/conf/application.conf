# 根据不同项目选择不同配置环境,配置项不变
init-config-type = "local-develop"
local-develop {
  job {
    # job任务名称前缀
    name.prefix = "flink_local_train_"
    # 流计算程序默认处理并行度
    default.parallelism = 4
    # Sink算子单独写并行度,防止Flink内部数据积压
    sink.parallelism = 2
    checkpoint {
      # 是否开启checkpoint
      enable = true
      # checkpoint时间间隔
      interval = 30000
      # 指定checkpoint类型,本地测试可以设置为Memory（memory、hdfs）
      type = "MEMORY_STATE"
      # 指定为hdfs时候需要指定checkpoint路径 (hdfs://localhost:9000/user/flink/checkpoints)
      path = ""
      # checkpoint超时时间
      timeout = 60000
      # 两次CheckPoint中间最小时间间隔
      min.pause.between = 500
      # 同时允许多少个Checkpoint在做快照
      current.checkpoints = 1
      # job遇到问题时,默认使用FixedDelayRestartStrategy重启策略的重试次数(3次)
      restart.attempts.times = 3
      # job遇到问题时,默认使用FixedDelayRestartStrategy重启策略的的每次重启时间间隔(20秒)
      restart.attempts.interval = 20000
    }
  }
  kafka {
    # 集群地址
    bootstrap.servers = "localhost:9092"
    # 每个Batch要存放size字节数据后才可以发送出去
    batch.size = "131072"
    # Batch创建之后,过多久发送出去
    linger.ms = "100"
    # 缓存大小
    buffer.memory = "67108864"
    # key 序列化
    key.serializer = "org.apache.kafka.common.serialization.StringSerializer"
    # value 序列化
    value.serializer = "org.apache.kafka.common.serialization.StringSerializer"
    # 消费者组
    group.id = "local_group"
    # 间隔多久（interval）获取一次kakfa的元数据,防止Kafka的topic进行扩容，出现丢数据的情况。大于0开启
    partition.discover.millis = 30000
    # Topic用于测试
    topic {
      string.topic: "fk_string_topic"
      json.topic: "fk_json_topic"
      kv1.topic: "fk_kv1_topic"
      kv2.topic: "fk_kv2_topic"
      event.topic: "fk_event_topic"
      sensor.topic: "fk_sensor_topic"
    }
  }
  redis {
    host: "localhost"
    port: 6379
  }
  mysql {
    url: "jdbc:mysql://localhost:3306/test?useUnicode=true&characterEncoding=utf-8&useSSL=false"
    driver: "com.mysql.jdbc.Driver"
    max-pool-size: 20
    max-idle-time: 1000
    user: "root"
    password: "1234"
  }
  file {
    local-file-dir: "file:///Users/lipan/app/data/flink-sink/"
    hdfs-file: ""
  }
}





